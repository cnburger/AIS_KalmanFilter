{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import math\n",
    "import datetime\n",
    "import scipy as sp\n",
    "import utm\n",
    "\n",
    "# For a bigger output image\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsampling time-intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_obs_time(df_in, time_interval_sec, obs_per_interval):\n",
    "\n",
    "    obs = obs_per_interval\n",
    "    time_inteval = time_interval_sec\n",
    "\n",
    "    #Max and min time\n",
    "    maxtime = max(df_in['datetimestamp'].values)\n",
    "    mintime = min(df_in['datetimestamp'].values)\n",
    "\n",
    "    #Total number of time sections in the data\n",
    "    total_iter = int(maxtime/time_inteval) +1\n",
    "\n",
    "    \n",
    "    #start interval, inclusive\n",
    "    lowerbound = mintime \n",
    "    #initial size, exclusive\n",
    "    upperbound = time_inteval \n",
    "\n",
    "    #Result DATAFRAME\n",
    "    df_sub_result = df_in.copy(deep = True)\n",
    "    df_sub_result = df_sub_result.iloc[0:0] #drop all entries in the dataframe\n",
    "\n",
    "    for subset_walk in np.arange(1,total_iter+2,1):#each subset present\n",
    "        boolean_selection = ((lowerbound < df_in['datetimestamp']) & (df_in['datetimestamp'] <= upperbound)).values\n",
    "\n",
    "        #subset for this interval\n",
    "        time_subset = copy.deepcopy(df_in.iloc[boolean_selection,:])\n",
    "\n",
    "        # subsampling the time sibset\n",
    "        if obs < len(time_subset): #if the no of observations is lessthat the total in the timestep continue, else nothing\n",
    "            for subsample in np.arange(0,len(time_subset), obs): #step with size = obs to sample each value in the set\n",
    "                df_sub_result = df_sub_result.append(time_subset.iloc[subsample,:])\n",
    "\n",
    "        #update bounds\n",
    "        #start interval, inclusive\n",
    "        lowerbound = copy.deepcopy(upperbound)\n",
    "        upperbound = time_inteval*subset_walk\n",
    "\n",
    "    return df_sub_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other functions needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_stats (df_in):\n",
    "    print(\"Length:\",len(df_in['datetimestamp']))\n",
    "    print(\"Total time:\",max(df_in['datetimestamp']))\n",
    "    print(\"Min Long:\",min(df_in['long']))\n",
    "    print(\"Max Long:\",max(df_in['long']))\n",
    "    print(\"Min lat:\",min(df_in['lat']))\n",
    "    print(\"Max lat:\",max(df_in['lat']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman - Conversions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cog(data_in):\n",
    "    return (data_in)*np.pi/180 #convert to radians\n",
    "\n",
    "def convert_rot(data_in):\n",
    "    return (data_in/60)*np.pi/180 #rad per second\n",
    "    \n",
    "def convert_sog(data_in):\n",
    "    return data_in*0.5144444444 #meter per second\n",
    "\n",
    "def convert_dataset(data_in, time_interval_sub, each_obs_sub):\n",
    "    #Converting time date:\n",
    "    df_sorted = copy.deepcopy(data_in.sort_values(by = 'datetimestamp', ascending = True ))\n",
    "    #Getting the date of the first observation\n",
    "    first_obs_date = df_sorted.iloc[0,6]\n",
    "\n",
    "    #Subtracting the dates to get the seconds from start to finish\n",
    "    df_sorted['datetimestamp'] = ((pd.to_datetime(df_sorted['datetimestamp']) - pd.to_datetime(first_obs_date)).dt.total_seconds())\n",
    "\n",
    "    #Sub sample time interval in seconds, after dates has been converted to startin at 0 sec to 5000s (example)\n",
    "    test = subsample_obs_time(df_sorted, time_interval_sub, each_obs_sub)\n",
    "    df_sorted = copy.deepcopy(test)\n",
    "    \n",
    "\n",
    "    #Conversion of Course over ground\n",
    "    df_sorted['cog'] = convert_cog(df_sorted['cog'])\n",
    "    \n",
    "    #Convert Speed over ground to mps\n",
    "    df_sorted['sog'] = convert_sog(df_sorted['sog'])\n",
    "    \n",
    "    #Convert rate of turn \n",
    "    df_sorted['rot'] = convert_rot(df_sorted['rot'])\n",
    "    \n",
    "    #Making the order same as testset    \n",
    "    df_sorted = df_sorted[['datetimestamp', 'lat', 'long', 'cog', 'sog','rot']]\n",
    "    \n",
    "    # Caluclating the the cartesian coordinates\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    #initial cartesian\n",
    "    init_utm = utm.from_latlon(df_sorted['lat'].values[0], df_sorted['long'].values[0])\n",
    "    X.append(init_utm[0])   #adding X coordinate\n",
    "    Y.append(init_utm[1])   #Adding Y coordinate\n",
    "\n",
    "    delta_time = [] #calculating delta time\n",
    "    delta_time.append(0)\n",
    "    for i in np.arange(1, len(df_sorted['datetimestamp']),1):\n",
    "        delta_time.append(int(df_sorted['datetimestamp'].values[i]) - int(df_sorted['datetimestamp'].values[i-1]))\n",
    "        #Caclulcating coordinates\n",
    "        ans = utm.from_latlon(df_sorted['lat'].values[i], df_sorted['long'].values[i])\n",
    "        #Adding the cartesian coordinates per time step\n",
    "        X.append(copy.deepcopy(ans[0]))\n",
    "        Y.append(copy.deepcopy(ans[1]))\n",
    "    \n",
    "   \n",
    "    #Adding the delta time\n",
    "    df_sorted.insert(1,'deltatime',delta_time) \n",
    "    #Adding cartesian coordiantes\n",
    "    df_sorted['lat'] = Y\n",
    "    df_sorted['long'] = X\n",
    "   \n",
    "    return df_sorted   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for the Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mat_A(deltaTime):\n",
    "    A = np.identity(4)\n",
    "    A[0,2] = deltaTime\n",
    "    A[1,3] = deltaTime\n",
    "    return A\n",
    "\n",
    "def predict_state(A, X_prev, a_x, a_y, deltaTIME):\n",
    "        \n",
    "    Bu_k = np.array([[a_x*deltaTIME*deltaTIME/2],\n",
    "                     [a_y*deltaTIME*deltaTIME/2],\n",
    "                     [a_x*deltaTIME],\n",
    "                     [a_y*deltaTIME]])\n",
    "    \n",
    "    pred_state = A.dot(X_prev) + Bu_k\n",
    "    return pred_state\n",
    "\n",
    "def pred_err_cov(A, Pk, Q):\n",
    "    return A.dot(Pk).dot(np.transpose(A)) + Q\n",
    "\n",
    "def Kalman_gain(P_k, H, R):\n",
    "    above = P_k.dot(np.transpose(H))\n",
    "    bottom = np.linalg.inv(H.dot(P_k).dot(np.transpose(H)) + R)\n",
    "    return above.dot(bottom)\n",
    "\n",
    "def adjust_pred_state(pred_state, Kk,z_k,H):\n",
    "    #Where z_k == the real observed value to adjust for the errors made\n",
    "    return pred_state + Kk.dot(z_k - H.dot(pred_state))\n",
    "\n",
    "def update_err_cov(I,Kk,H,P_k):\n",
    "    return (I - Kk.dot(H)).dot(P_k)    \n",
    "\n",
    "def calc_a_xy(arr_in, arr_prev):\n",
    "    \n",
    "    sog_now = np.around(arr_in[5],8)\n",
    "    sog_prev = np.around(arr_prev[5],8)\n",
    "    \n",
    "    cog_now = np.around(arr_in[4],8)\n",
    "    cog_prev = np.around(arr_prev[4],8)\n",
    "    \n",
    "    rot_now = np.around(arr_in[6],6)    \n",
    "    delta_time = arr_in[1]   \n",
    "    a_x = (sog_now*np.cos(cog_now + rot_now*delta_time) - sog_prev*np.cos(cog_prev))/delta_time    \n",
    "    a_y = (sog_now*np.sin(cog_now + rot_now*delta_time) - sog_prev*np.sin(cog_prev))/delta_time \n",
    "    \n",
    "    return a_x, a_y\n",
    "\n",
    "\n",
    "def convert_state(arr_in):\n",
    "    sog = arr_in[5]\n",
    "    cog = arr_in[4]    \n",
    "    x = arr_in[2]\n",
    "    y = arr_in[3]        \n",
    "    Vx = sog*np.cos(cog)\n",
    "    Vy = sog*np.sin(cog)\n",
    "    \n",
    "    return_arr = np.array([[x],[y],[Vx],[Vy]])\n",
    "    \n",
    "    return return_arr\n",
    "\n",
    "def extract_long_lat_covariance(mat_in):\n",
    "    Var1 = mat_in[0,0]\n",
    "    Var2 = mat_in[1,1]\n",
    "    Cov12 = mat_in[0,1]\n",
    "    \n",
    "    result = np.array([[Var1,Cov12],[Cov12,Var2]])\n",
    "    return result\n",
    "\n",
    "def set_R(R_in, arr_x, arr_y, arr_Vx, arr_Vy):\n",
    "    var_x = np.var(arr_x)\n",
    "    var_y = np.var(arr_y)\n",
    "    var_Vx = np.var(arr_Vx)\n",
    "    var_Vy = np.var(arr_Vy)\n",
    "    \n",
    "    R_in[0,0] = var_x\n",
    "    R_in[1,1] = var_y\n",
    "    R_in[2,2] = var_Vx\n",
    "    R_in[3,3] = var_Vy\n",
    "    \n",
    "    return R_in\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.arange(0,10)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "test[(k-5):k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Kalman Filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_arr = []\n",
    "ay_arr= []\n",
    "Pk_save_states = []\n",
    "def myKalman(pd_final, R,Q,P_k,show_plots = True):\n",
    "    global ax_arr, ay_arr, df_final,Pk_save_states\n",
    "    \n",
    "    H = np.identity(4)\n",
    "    I = np.identity(4)   \n",
    "\n",
    "    # Kalman Initial state\n",
    "    X_state = np.array([[0],[0],[0],[0]])\n",
    "    \n",
    "    # Lists to append data and values to, saving ttansitions:\n",
    "    ax_arr = []\n",
    "    ay_arr = []\n",
    "    X_save_states = []\n",
    "    Pk_save_states = []\n",
    "    Pk_save_states.append(copy.deepcopy(P_k))\n",
    "\n",
    "    data_counter = 1 # counter for the original data set obsevations\n",
    "\n",
    "    max_time = int(max(pd_final.iloc[:,0]))\n",
    "    min_time = int(min(pd_final.iloc[:,0]))\n",
    "\n",
    "    data_counter_stop = max_time-min_time\n",
    "\n",
    "    \n",
    "    realSpeedX = []\n",
    "    realSpeedY = []\n",
    "    realSpdCount = []\n",
    "    for i in np.arange(0,max_time,1):\n",
    "        \n",
    "\n",
    "        '''If we observe the value we observe this'''\n",
    "        if(i == 0 or (int(pd_final.iloc[data_counter,0]) == i and data_counter < data_counter_stop)):\n",
    "            zk_prev = pd_final.iloc[data_counter-1,:].values #previous observation\n",
    "            z_k = pd_final.iloc[data_counter,:].values # convert to numpy array -observed value\n",
    "\n",
    "            delta_TIME = copy.deepcopy(z_k[1]) #difference in time\n",
    "            A = get_mat_A(delta_TIME)\n",
    "\n",
    "            #Acceleration\n",
    "            ax, ay = calc_a_xy(z_k,zk_prev) \n",
    "            ax_arr.append(ax)\n",
    "            ay_arr.append(ay)\n",
    "\n",
    "            z_k = copy.deepcopy(convert_state(z_k)) #convert state\n",
    "            realSpdCount.append(i)\n",
    "            realSpeedX.append(z_k[2][0])\n",
    "            realSpeedY.append(z_k[3][0])\n",
    "            X_state = copy.deepcopy(convert_state(zk_prev))\n",
    "\n",
    "            #Kalman Predict--------------------------------------------------------------------------------------------\n",
    "            X_state = copy.deepcopy(predict_state(A, X_state, ax, ay, delta_TIME))\n",
    "            P_k =  copy.deepcopy(pred_err_cov(A, P_k, Q))\n",
    "\n",
    "            #Kalman Measuremenet update--------------------------------------------------------------------------------\n",
    "            Kalman_k = copy.deepcopy(Kalman_gain(P_k, H, R))\n",
    "            X_state = copy.deepcopy(adjust_pred_state(X_state, Kalman_k, z_k, H))\n",
    "            P_k = copy.deepcopy(update_err_cov(I, Kalman_k, H, P_k))\n",
    "\n",
    "\n",
    "            #increment counter\n",
    "            data_counter += 1\n",
    "\n",
    "            #Saving states\n",
    "            X_save_states.append(copy.deepcopy(X_state))\n",
    "            Pk_save_states.append(copy.deepcopy(P_k))\n",
    "\n",
    "        else:\n",
    "            '''This code will be excecuted when we have no observation'''\n",
    "            ay = 0\n",
    "            ax = 0\n",
    "            A = get_mat_A(1)\n",
    "            #Kalman Predict --------------------------------------------------------------------------\n",
    "            X_state = copy.deepcopy(predict_state(A, X_state, ax, ay, 1))\n",
    "            P_k =  copy.deepcopy(pred_err_cov(A,P_k,Q))\n",
    "\n",
    "            #Saving states\n",
    "            Pk_save_states.append(copy.deepcopy(P_k))\n",
    "            X_save_states.append(copy.deepcopy(X_state))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Saving the coordinates:\n",
    "    X_coord = []\n",
    "    Y_coord = []\n",
    "    Pk_coord  = []\n",
    "    SpeedX = []\n",
    "    SpeedY = []\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(0,len(X_save_states)):\n",
    "        if i > 1 and  i % 1 == 0:\n",
    "            X_coord.append(X_save_states[i][0][0])\n",
    "            Y_coord.append(X_save_states[i][1][0])\n",
    "            SpeedX.append(X_save_states[i][2][0]) #Speed in X axis\n",
    "            SpeedY.append(X_save_states[i][3][0]) #Speed in Y axis\n",
    "            \n",
    "            #Pk_coord.append(extract_long_lat_covariance(Pk_save_states[i]))\n",
    "\n",
    "    #Extracting the original data:\n",
    "    X_orig = copy.deepcopy(pd_final.iloc[:,2])\n",
    "    Y_orig = copy.deepcopy(pd_final.iloc[:,3])\n",
    "\n",
    "    \n",
    "    if(show_plots):\n",
    "        #Graph outputs:\n",
    "        \n",
    "        x_y_size = 14\n",
    "        title_size = 17\n",
    "        \n",
    "        '''Speed in the X-axis'''\n",
    "        plt.figure(figsize = (10,5))\n",
    "        plt.plot(np.arange(0,len(SpeedX),1), SpeedX, '-', color = 'royalblue',linewidth = 1)\n",
    "        plt.plot(realSpdCount, realSpeedX,'o-', color = 'red', markersize = 2)\n",
    "        plt.title(\"Latitudinal Speed Over Ground - DKF\", size =  title_size)\n",
    "        legend_data = [\"DKF Estimation\",\"Observed SOG\"]\n",
    "        plt.legend(legend_data,loc = \"lower center\",fontsize =  x_y_size)\n",
    "        plt.xlabel(\"Time (s)\", size = x_y_size)\n",
    "        plt.ylabel(\"Speed over ground (m/s)\", size = x_y_size)\n",
    "        plt.yticks(size = x_y_size)\n",
    "        plt.xticks(size = x_y_size)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        '''Speed in the Y-axis'''\n",
    "        plt.figure(figsize = (10,5))\n",
    "        plt.plot(np.arange(0,len(SpeedY),1),SpeedY, '-',  color = 'royalblue',linewidth = 1)\n",
    "        plt.plot(realSpdCount, realSpeedY,'o-', color = 'red', markersize = 2)\n",
    "        legend_data = [\"DKF Estimation\",\"Observed SOG\"]\n",
    "        plt.legend(legend_data,loc = 'best', fontsize = x_y_size)\n",
    "        plt.title(\"Longitudinal Speed Over Ground - DKF\", size =  title_size)\n",
    "        plt.xlabel(\"Observation number\", size = x_y_size)\n",
    "        plt.ylabel(\"Speed over ground (m/s))\", size = x_y_size)\n",
    "        plt.yticks(size = x_y_size)\n",
    "        plt.xticks(size = x_y_size)\n",
    "        plt.show()\n",
    "\n",
    "        '''X coordinate tracking'''\n",
    "        plt.plot(realSpdCount,Y_orig[0:(len(realSpdCount))], \"ro\")\n",
    "        plt.plot(np.arange(0,len(Y_coord),1),Y_coord, \"b.\")\n",
    "        legend_data = [\"Original Observation\",\"DKF Estiamte\"]\n",
    "        plt.legend(legend_data,loc = 'upper center', fontsize = x_y_size)\n",
    "        plt.title(\"Latitudinal coordinate tracking: $\\hat{x} $ vs $x$\", size =  title_size)\n",
    "        plt.xlabel(\"Observation Number\", size = x_y_size)\n",
    "        plt.ylabel(\"Latitude (UTM)\", size = x_y_size)\n",
    "        plt.yticks(size = x_y_size)\n",
    "        plt.xticks(size = x_y_size)\n",
    "        plt.show()\n",
    "\n",
    "        '''Y coordinate tracking'''\n",
    "        plt.plot(realSpdCount,X_orig[0:(len(realSpdCount))], \"ro\")\n",
    "        plt.plot(np.arange(0,len(X_coord),1),X_coord, \"b.\")\n",
    "        plt.title(\"Longitudinal coordinate tracking: $\\hat{y} $ vs $y$\", size =  title_size)\n",
    "        legend_data = [\"Original Observation\",\"DKF Estimate\"]\n",
    "        plt.legend(legend_data,loc = 'best', fontsize = x_y_size)\n",
    "        plt.xlabel(\"Observation Number\", size = x_y_size)\n",
    "        plt.ylabel(\"Longitude (UTM)\", size = x_y_size)\n",
    "        plt.yticks(size = x_y_size)\n",
    "        plt.xticks(size = x_y_size)\n",
    "        plt.show()\n",
    "        \n",
    "        '''XY coordinate tracking'''\n",
    "        plt.figure(figsize = (9,4.5))\n",
    "        plt.plot(Y_orig[0:(len(realSpdCount))],X_orig[0:(len(realSpdCount))],'o-', color = 'red', markersize = 3)\n",
    "        plt.plot(Y_coord,X_coord, '-',  color = 'royalblue',linewidth = 3)\n",
    "        plt.title(\"Predicted Trajectory - DKF\", size = title_size)\n",
    "        legend_data = [\"Original Trajectory\",\"DKF Estimate\"]\n",
    "        plt.legend(legend_data,loc = 'best', fontsize = x_y_size)\n",
    "        plt.xlabel(\"Latitude (UTM)\", size = x_y_size)\n",
    "        plt.ylabel(\"Longitude (UTM)\", size = x_y_size)\n",
    "        plt.yticks(size = x_y_size)\n",
    "        plt.xticks(size = x_y_size)\n",
    "        plt.show()\n",
    "   \n",
    "    \n",
    "    return np.array(X_coord),np.array(Y_coord),X_orig,Y_orig,ax_arr,ay_arr, SpeedX, SpeedY, np.array(realSpdCount)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dataset & getting linear trajectory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_dataset = None\n",
    "import os\n",
    "print(os.getcwd())\n",
    "pd_dataset = pd.read_csv(r\"304927000.csv\")\n",
    "\n",
    "#Boundaries sampling from and to\n",
    "lower = 50\n",
    "upper = 750\n",
    "x_y_size = 14\n",
    "title_size = 17\n",
    "plt.plot(pd_dataset['long'].values[lower:upper],pd_dataset['lat'].values[lower:upper],'b.')\n",
    "plt.title(\"Trajectory\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (9,5))\n",
    "\n",
    "mean_speed = np.mean(pd_dataset['sog'].values[lower:upper])\n",
    "median_speed = np.median(pd_dataset['sog'].values[lower:upper])\n",
    "plt.axhline(y = mean_speed, linestyle = \"--\", alpha = 0.85, color = \"darkgreen\" )\n",
    "plt.axhline(y = median_speed, linestyle = \"--\", alpha = 0.85, color = \"darkorange\" )\n",
    "plt.plot(np.arange(0,len(pd_dataset['sog'].values[lower:upper]),1),pd_dataset['sog'].values[lower:upper],'o-', color = 'r',alpha = 0.95,markersize = 3.8, linewidth = 1)\n",
    "\n",
    "legend_data = [str(\"Average Speed \"+ str(np.round(mean_speed,2))+\" kts\"), \n",
    "               str(\"Median Speed \"+ str(np.round(median_speed,2))+\" kts\"),\"Observed Speed\"]\n",
    "plt.legend(legend_data,loc = 'best', fontsize = 12)\n",
    "\n",
    "plt.title(\"Observed SOG for Each Observation\",size = title_size)\n",
    "plt.xlabel(\"Observation Number\", size = x_y_size)\n",
    "plt.ylabel(\"Speed Over Ground (knots)\",size = x_y_size)\n",
    "plt.yticks(size = x_y_size)\n",
    "plt.xticks(size = x_y_size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUB SAMPLING & TRAJECTORY EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = 300\n",
    "upper = 750\n",
    "myrange = np.arange(lower,upper,1) #to cut the part thats goint to be used\n",
    "\n",
    "pd_dataset_new = convert_dataset(pd_dataset.iloc[myrange,:].reset_index(drop = True),240,1)\n",
    "#The pandas dataframe index needs to be resetted so that the indexing does'nt play a factor\n",
    "df_sampled = copy.deepcopy(pd_dataset_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting some stats on the extracted trajectory\n",
    "dataframe_stats(pd_dataset_new)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up $P_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMO Standards\n",
    "var_X = 10\n",
    "var_Y = 10\n",
    "var_spdX = 0.3\n",
    "var_spdY = 0.3\n",
    "\n",
    "P_k = np.array([[var_X],[var_Y],[var_spdX],[var_spdY]]).dot(np.transpose(\n",
    "      np.array([[var_X],[var_Y],[var_spdX],[var_spdY]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up $Q$:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMO standards:\n",
    "var_X = 10\n",
    "var_Y = 10\n",
    "var_spdX = 0.3\n",
    "var_spdY = 0.3\n",
    "\n",
    "Q = np.array([[var_X],[var_Y],[var_spdX],[var_spdY]]).dot(np.transpose(\n",
    "      np.array([[var_X],[var_Y],[var_spdX],[var_spdY]]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up R:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.diag(np.diag(P_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Kalman filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_samp_pred, Y_samp_pred, X_samp_orig, Y_samp_orig, _, _, _, _, Kalman_observed_sec = myKalman(df_sampled, R,Q,P_k,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This will be a function of time\n",
    "We will be estimating X Y SpeedOverGround CourseOverGround. With this we can calculate the speed in the X and Y axis respectively.\n",
    "\n",
    "#### Idea:\n",
    "$X_{new} =  X_{old} + Speed_{x-axis} \\times time$\n",
    "\n",
    "$Y_{new} =  Y_{old} + Speed_{y-axis} \\times time$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the linear regression model from Scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def AIS_linear(df_in, lin_remember_history, show_plots = True):\n",
    "    '''\n",
    "        df_in:  Pandas Data Frame,\n",
    "                AIS data frame with more or less linear trajectory\n",
    "        lin_remember_history: integer,  (default = 5)\n",
    "                This integer value should specify the number of historical observations the linear method \n",
    "                are based on\n",
    "    '''\n",
    "    #REMEMBER HISTORY OF MODEL\n",
    "    remember_history = lin_remember_history \n",
    "    \n",
    "    # Extracting the values from the dataframe\n",
    "    X_have = df_in['long'].values\n",
    "    Y_have = df_in['lat'].values\n",
    "    time = df_in['datetimestamp'].values.astype(int) #exctracting time as an array\n",
    "    #Extracting speed\n",
    "    speed = df_in['sog'].values\n",
    "    course = df_in['cog'].values\n",
    "      \n",
    "    #Intitial parameters\n",
    "    current_course = course[0] #initial course value. It remains constant only update if a new value comes\n",
    "    \n",
    "    #Time range in seconds\n",
    "    sec_range = np.arange(0,int(max(time))+1,1)\n",
    "    \n",
    "    sec_observed = [] # to rememember when a second was an observed second\n",
    "\n",
    "    \n",
    "    #To save historical times\n",
    "    time_history = np.array([]) # thislist will keep track of the last times recorded, intitial time == 0\n",
    "    speed_history = np.array([]) # this list keep track of the speeds recorded\n",
    "    pred_speed = np.array([]) # this list stores the predicted values\n",
    "\n",
    "    #Speed in X Y\n",
    "    pred_speedX =  []\n",
    "    pred_speedY = []\n",
    "    orig_speedX = []\n",
    "    orig_speedY = []\n",
    "\n",
    "    #Saving prediction\n",
    "    speed_pred = []\n",
    "\n",
    "    # Saving the X and Y predictions\n",
    "    X_loc_pred = []\n",
    "    Y_loc_pred = []\n",
    "    \n",
    "    # Setting initial values\n",
    "    X_new =  X_have[0]\n",
    "    Y_new = Y_have[0]\n",
    "    X_error = 0\n",
    "    Y_error = 0\n",
    "\n",
    "\n",
    "    #Initial Regression guess with a speed of 4.8, just a random speed value nothing special about it\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(np.array([0]).reshape(-1,1),np.array([4.8]).reshape(-1,1))\n",
    "\n",
    "    #counting the entries to appropriatly measure difference\n",
    "    counter_sec = 0 \n",
    "    for sec in sec_range:    \n",
    "        '''IF WE OBSERVE the value'''\n",
    "\n",
    "        if(time[counter_sec] == sec):\n",
    "            sec_observed.append(sec) #We observed index at this second\n",
    "\n",
    "            if len(time_history) > remember_history : #if the list is long enough\n",
    "                speed_history = np.delete(speed_history,0) #remove 1st entry in array\n",
    "                time_history = np.delete(time_history,0) # remove 1st entry in array\n",
    "\n",
    "            #Saving the last moments up to specified history amount    \n",
    "            time_history = np.append(time_history,sec)\n",
    "            speed_history = np.append(speed_history,speed[counter_sec])\n",
    "            current_course =  course[counter_sec]\n",
    "\n",
    "            #Fit a new model\n",
    "            reg = LinearRegression()\n",
    "            reg.fit(time_history.reshape(-1,1),speed_history.reshape(-1,1))\n",
    "\n",
    "            #PREDICTING SPEED\n",
    "            predict_speed_value = reg.predict(np.array([sec]).reshape(-1,1))\n",
    "            pred_speed = np.append(pred_speed,predict_speed_value)\n",
    "\n",
    "            #SPEED IN X AN Y AXIS\n",
    "            pred_X_axis_speed = predict_speed_value[0][0]*np.cos(current_course)\n",
    "            pred_speedX.append(pred_X_axis_speed)   \n",
    "            pred_Y_axis_speed = predict_speed_value[0][0]*np.sin(current_course)\n",
    "            pred_speedY.append(pred_Y_axis_speed)\n",
    "\n",
    "            # SAVING ORIGINAL VALUES\n",
    "            orig_speedX.append(speed[counter_sec]*np.cos(course[counter_sec]))\n",
    "            orig_speedY.append(speed[counter_sec]*np.sin(course[counter_sec]))\n",
    "\n",
    "            #PREDICTING MOVEMENT IN X AND Y\n",
    "            X_new = X_new + pred_X_axis_speed\n",
    "            X_error = X_have[counter_sec] - X_new  # to update next position to the correct spot c\n",
    "            X_loc_pred.append(X_new)\n",
    "\n",
    "            Y_new = Y_new + pred_Y_axis_speed\n",
    "            Y_error = Y_have[counter_sec] - Y_new  # to update next position to the correct spot c\n",
    "            Y_loc_pred.append(Y_new)\n",
    "\n",
    "            #Counter to walk through list\n",
    "            counter_sec += 1   \n",
    "        else:\n",
    "            #JUST PERDICT\n",
    "            predict_speed_value = reg.predict(np.array([sec]).reshape(-1,1))\n",
    "            #SPEED\n",
    "            pred_speed = np.append(pred_speed, predict_speed_value)\n",
    "            #SPEED IN X AN Y AXIS \n",
    "            pred_X_axis_speed = predict_speed_value[0][0]*np.cos(current_course)\n",
    "            pred_speedX.append(pred_X_axis_speed)   \n",
    "            pred_Y_axis_speed = predict_speed_value[0][0]*np.sin(current_course)\n",
    "            pred_speedY.append(pred_Y_axis_speed)\n",
    "\n",
    "            #PREDICTING MOVEMENT IN X AND Y\n",
    "            X_new = X_new + pred_X_axis_speed + X_error\n",
    "            X_error = 0 #reset the error after the correction\n",
    "\n",
    "            Y_new = Y_new + pred_Y_axis_speed + Y_error\n",
    "            Y_error = 0 #reset the error after the correction\n",
    "            \n",
    "            Y_loc_pred.append(Y_new)\n",
    "            X_loc_pred.append(X_new)\n",
    "\n",
    "\n",
    "    \n",
    "    if(show_plots):\n",
    "        # PLOTTING - Functions\n",
    "#         plt.plot(sec_range,pred_speed,'r-')\n",
    "#         plt.plot(time,speed,\"b-\")\n",
    "#         legend_data = [\"Linear tracking\", \"Original data\"]\n",
    "#         plt.legend(legend_data,loc = 'best', fontsize = 16)\n",
    "#         plt.title(\"Linear speed tracking vs true speed\", size = 20)\n",
    "#         plt.ylabel(\"Speed over ground (m/s)\", size = 20)\n",
    "#         plt.xlabel(\"Time (s)\", size = 20)\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "        x_y_size = 12\n",
    "        title_size = 16\n",
    "        plt.figure(figsize = (10,5))\n",
    "        \n",
    "        \n",
    "        plt.plot(time,np.array(orig_speedX),'o-', color = 'red', markersize = 2)\n",
    "        plt.plot(sec_range,np.array(pred_speedX),'-', color = 'royalblue',linewidth = 1)\n",
    "        \n",
    "        legend_data = [\"Linear Tracking\", \"Original Data\"]\n",
    "        plt.legend(legend_data,loc = 'best', fontsize = x_y_size)\n",
    "        plt.title(\"Latitudinal Speed Over Ground - LRM\", size =  title_size)\n",
    "        plt.ylabel(\"Speed over ground (m/s)\", size = x_y_size)\n",
    "        plt.xlabel(\"Time (s)\", size = x_y_size)\n",
    "        plt.yticks(size = x_y_size)\n",
    "        plt.xticks(size = x_y_size)      \n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize = (10,5))\n",
    "        plt.plot(sec_range,np.array(pred_speedY),'o-', color = 'red', markersize = 2)\n",
    "        plt.plot(time,np.array(orig_speedY),'-', color = 'royalblue',linewidth = 1)\n",
    "        legend_data = [\"Linear Tracking\", \"Original Data\"]\n",
    "        plt.legend(legend_data,loc = 'best', fontsize = x_y_size)\n",
    "        plt.title(\"Longitudinal Speed Over Ground - LRM\", size =  title_size)\n",
    "        plt.xlabel(\"Time (s)\", size = x_y_size)\n",
    "        plt.ylabel(\"Speed over ground (m/s)\", size = x_y_size)\n",
    "        plt.yticks(size = x_y_size)\n",
    "        plt.xticks(size = x_y_size)\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(sec_range,np.array(X_loc_pred),'bo')\n",
    "        plt.plot(time,X_have,'r.')\n",
    "        legend_data = [\"Linear Method\", \"Original Data\"]\n",
    "        plt.legend(legend_data,loc = 'best', fontsize = x_y_size)\n",
    "        plt.title(\"Latitudinal coordinate tracking: $\\hat{x} $ vs $x$\", size = title_size)\n",
    "        plt.ylabel(\"Latitude (UTM)\", size = x_y_size)\n",
    "        plt.xlabel(\"Observation Number\", size = x_y_size)\n",
    "        plt.yticks(size = x_y_size)\n",
    "        plt.xticks(size = x_y_size)\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(sec_range,np.array(Y_loc_pred),'bo')\n",
    "        plt.plot(time,Y_have,'r.')\n",
    "        legend_data = [\"LRM Estimate\", \"Original Observation\"]\n",
    "        plt.legend(legend_data,loc = 'best', fontsize = x_y_size)\n",
    "        plt.title(\"Longitudinal coordinate tracking: $\\hat{y} $ vs $y$\", size = title_size)\n",
    "        plt.ylabel(\"Longitude (UTM)\", size = x_y_size)\n",
    "        plt.xlabel(\"Observation Number\", size = x_y_size)\n",
    "        plt.yticks(size = x_y_size)\n",
    "        plt.xticks(size = x_y_size)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize = (9,4.5))\n",
    "        \n",
    "        plt.plot(X_have, Y_have,'o-', color = 'red', markersize = 3)\n",
    "        plt.plot(X_loc_pred,Y_loc_pred, '-',  color = 'royalblue',linewidth = 3)\n",
    "        \n",
    "        legend_data = [\"Original Trajectory\",\"LRM Estimate\"]\n",
    "        plt.legend(legend_data,loc = 'best', fontsize = x_y_size)\n",
    "        plt.title(\"Predicted Trajectory - LRM\", size = title_size)\n",
    "        plt.ylabel(\"Longitude (UTM)\", size = x_y_size)\n",
    "        plt.xlabel(\"Latitude (UTM)\", size = x_y_size)\n",
    "        plt.yticks(size = x_y_size)\n",
    "        plt.xticks(size = x_y_size)\n",
    "        plt.show()   \n",
    "\n",
    "   \n",
    "    return np.array(X_loc_pred), np.array(Y_loc_pred), np.array(pred_speed), np.array(sec_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_samp_pred, Y_samp_pred, X_samp_orig, Y_samp_orig, _, _, _, _, Kalman_observed_sec = myKalman(df_sampled, R,Q,P_k,True)\n",
    "pred_linear_X, pred_linear_Y,pred_linear_SOG,linear_sec_ob = AIS_linear(df_origMMSI,5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_errors(df_orig,df_sub, pred_X, pred_Y, observed_sec,myTitle, show_plots = False ):\n",
    "    time_steps = df_orig['datetimestamp'].values.astype(int)   \n",
    "    \n",
    "    x_y_size = 14\n",
    "    title_size = 16\n",
    "    max_time = max(observed_sec)\n",
    "    time_steps = time_steps[time_steps <= max_time] \n",
    "    \n",
    "    \n",
    "    X_pred_orig = pred_X[time_steps]\n",
    "    Y_pred_orig = pred_Y[time_steps]  \n",
    "    \n",
    "    test = np.arange(0,len(X_pred_orig),1)\n",
    "    \n",
    "\n",
    "    X_orig = df_orig['long'].values[test]  \n",
    "    Y_orig = df_orig['lat'].values [test] \n",
    "    \n",
    "\n",
    "    \n",
    "    X_MSE = np.sum((X_orig - X_pred_orig )**2)/len(test)\n",
    "    Y_MSE = np.sum((Y_orig - Y_pred_orig )**2)/len(test)\n",
    "    \n",
    "    Euclid_AVG = np.sum(np.sqrt((X_orig - X_pred_orig)**2 + (Y_orig - Y_pred_orig )**2))/len(X_pred_orig)\n",
    "    \n",
    "    \n",
    "    X_error = X_orig - X_pred_orig\n",
    "    Y_error = Y_orig - Y_pred_orig \n",
    "    Euclid_err = np.sqrt((X_orig - X_pred_orig)**2 + (Y_orig - Y_pred_orig )**2)\n",
    "    \n",
    "    if(show_plots):\n",
    "        plt.figure(figsize = (10,5))\n",
    "        plt.plot(time_steps,X_error,'.')\n",
    "        plt.plot(time_steps,Y_error,'.')\n",
    "        plt.plot(time_steps,Euclid_err,'.')\n",
    "        plt.title(myTitle, size = title_size)\n",
    "        plt.xlabel(\"Time (s)\", size = x_y_size)\n",
    "        plt.ylabel(\"Error (m)\", size = x_y_size)\n",
    "        legend_lab = [\"Latitudinal\",\"Longitudinal\",\"Euclidean Distance\"]\n",
    "        plt.ylim(-500,500)\n",
    "        plt.yticks(size = x_y_size)\n",
    "        plt.xticks(size = x_y_size)\n",
    "        plt.legend(legend_lab, loc = \"lower center\", title = \"Errors\", ncol = 3, \n",
    "                   fontsize = x_y_size, title_fontsize = 14.5)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "        print(\"X_MSE\",X_MSE)\n",
    "        print(\"Y_MSE\",Y_MSE)\n",
    "        print(\"Euclid_AVG\",Euclid_AVG) \n",
    "    \n",
    "    return X_MSE, Y_MSE, Euclid_AVG,Euclid_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_dataset = None \n",
    "pd_dataset = pd.read_csv(r\"304927000.csv\")\n",
    "lower = 300\n",
    "upper = 750\n",
    "myrange = np.arange(lower,upper,1) #to cut the part thats goint to be used\n",
    "df_origMMSI = convert_dataset(pd_dataset.iloc[myrange,:].reset_index(drop = True),240,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mmsi_and_range = pd.DataFrame(columns=['MMSI','START', 'END'])\n",
    "\n",
    "arr_MMSI = np.array(['538004506.csv',\n",
    "                       '226105000.csv',\n",
    "                       '235097013.csv',\n",
    "                       '305714000.csv',\n",
    "                       '304519000.csv',\n",
    "                       '304927000.csv',\n",
    "                       '636092331.csv',\n",
    "                       '224389000.csv',\n",
    "                       '220540000.csv',\n",
    "                       '211286440.csv',\n",
    "                       '207138000.csv',\n",
    "                       '207138000.csv',\n",
    "                       '215901000.csv',\n",
    "                       '227146400.csv',\n",
    "                       '314237000.csv',\n",
    "                       '565494000.csv',\n",
    "                       '244740921.csv',\n",
    "                       '227330000.csv',\n",
    "                       '227372000.csv',\n",
    "                       '228130000.csv',\n",
    "                       '228727000.csv',\n",
    "                       '227988000.csv',\n",
    "                       '244925000.csv',\n",
    "                       '247224200.csv',\n",
    "                       '249104000.csv',\n",
    "                       '518866000.csv',\n",
    "                       '276700000.csv',\n",
    "                       '577228000.csv',\n",
    "                       '227558000.csv',\n",
    "                       '227364000.csv'])\n",
    "# print(np.array(['../NARI MMSI CSVs/']),arr_MMSI)\n",
    "\n",
    "\n",
    "MMSI_starts = np.array([10 ,420,200,5  ,300,300,4358,128,120,2210,150,790 ,50 ,960 ,1000,20 ,5200,\n",
    "               50 ,10 ,20 ,100,1600,0  ,210,200,350,300,300,350,495])\n",
    "MMSI_ends   = np.array([350,850,400,600,750,750,4850,375,560,2800,590,1200,600,1500,1500,550,5600,\n",
    "               550,420,450,500,2000,450,620,650,800,700,750,800,850])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_MMSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter & Linear Funcition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_sequence = np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21])\n",
    "df_results = pd.DataFrame(columns=['MMSI',\n",
    "                                   'Method', \n",
    "                                   'Sub1',\n",
    "                                    'Sub2',\n",
    "                                    'Sub3',\n",
    "                                    'Sub4',\n",
    "                                    'Sub5',\n",
    "                                    'Sub6',\n",
    "                                    'Sub7',\n",
    "                                    'Sub8',\n",
    "                                    'Sub9',\n",
    "                                    'Sub10',\n",
    "                                    'Sub11',\n",
    "                                    'Sub12',\n",
    "                                    'Sub13',\n",
    "                                    'Sub14',\n",
    "                                    'Sub15',\n",
    "                                    'Sub16',\n",
    "                                    'Sub17',\n",
    "                                    'Sub18',\n",
    "                                    'Sub19',\n",
    "                                    'Sub20',\n",
    "                                    'Sub21'])\n",
    "\n",
    "my_sub_sec = np.arange(240,1800,60)\n",
    "\n",
    "for sub_sec_count in my_sub_sec:\n",
    "    print(\"\\n\\n\\n MY SUBSAMPLE LENGTH:\", sub_sec_count, \"\\n\\n\\n\")\n",
    "\n",
    "    for data_set in range(0,len(arr_MMSI)):\n",
    "        my_MMSI = str(\"./NARI MMSI CSVs/\"+arr_MMSI[data_set])\n",
    "        start = MMSI_starts[data_set] \n",
    "        end = MMSI_ends[data_set]\n",
    "\n",
    "        print(\"\\n\\n\\nMMSI NO:\",my_MMSI,\"START:\", start, \"END:\", end)\n",
    "\n",
    "        pd_dataset = pd.read_csv(my_MMSI)\n",
    "        lower = start\n",
    "        upper = end\n",
    "        myrange = np.arange(lower,upper,1) #to cut the part thats goint to be used\n",
    "        df_origMMSI = convert_dataset(pd_dataset.iloc[myrange,:].reset_index(drop = True),240,1)\n",
    "\n",
    "\n",
    "        Kalman_error_EuclidXY =   []\n",
    "        Linear_error_EuclidYX =   []\n",
    "\n",
    "        for sub_sample_data in my_sequence:\n",
    "            #print(\"\\n\\n\\n\\n\\n\\nSUB SAMPLE SIZE: \",sub_sample_data )\n",
    "            df_subMMSI = convert_dataset(pd_dataset.iloc[myrange,:].reset_index(drop = True),sub_sec_count,sub_sample_data)\n",
    "\n",
    "            Kalman_X_pred, Kalman_Y_pred, X_samp_orig, Y_samp_orig, _, _, _,_,Kalman_observed_sec = myKalman(df_subMMSI, R,Q,P_k, False)\n",
    "            #print('------------------------------------- LINEAR METHOD ---------------------------------------')\n",
    "            pred_linear_X, pred_linear_Y,pred_linear_SOG,linear_sec_ob = AIS_linear(df_subMMSI,5,False)\n",
    "\n",
    "            #print('------------------------------------- KALMAN ERROR ---------------------------------------')\n",
    "            Kalman_X_MSE, Kalman_Y_MSE, Kalman_Euclid_AVG, _ = calculate_errors(df_origMMSI,df_subMMSI,Kalman_Y_pred,Kalman_X_pred,Kalman_observed_sec, False)\n",
    "            #print('------------------------------------- LINEAR ERROR ---------------------------------------')\n",
    "            Linear_X_MSE, Linear_Y_MSE, Linear_Euclid_AVG,_ = calculate_errors(df_origMMSI,df_subMMSI,pred_linear_X,pred_linear_Y,linear_sec_ob, False)\n",
    "\n",
    "            #APPENDINGS\n",
    "\n",
    "            Kalman_error_EuclidXY.append(Kalman_Euclid_AVG)\n",
    "            Linear_error_EuclidYX.append(Linear_Euclid_AVG)\n",
    "\n",
    "        Kalman_error_EuclidXY = np.array(Kalman_error_EuclidXY)\n",
    "        Linear_error_EuclidYX = np.array(Linear_error_EuclidYX)\n",
    "\n",
    "        df_results = df_results.append({'MMSI': my_MMSI,'Method': 'Kalman', \n",
    "                                        'Sub1':Kalman_error_EuclidXY[0],\n",
    "                                        'Sub2':Kalman_error_EuclidXY[1],\n",
    "                                        'Sub3':Kalman_error_EuclidXY[2],\n",
    "                                        'Sub4':Kalman_error_EuclidXY[3],\n",
    "                                        'Sub5':Kalman_error_EuclidXY[4],\n",
    "                                        'Sub6':Kalman_error_EuclidXY[5],\n",
    "                                        'Sub7':Kalman_error_EuclidXY[6],\n",
    "                                        'Sub8':Kalman_error_EuclidXY[7],\n",
    "                                        'Sub9':Kalman_error_EuclidXY[8],\n",
    "                                        'Sub10':Kalman_error_EuclidXY[9],\n",
    "                                        'Sub11':Kalman_error_EuclidXY[10],\n",
    "                                        'Sub12':Kalman_error_EuclidXY[11],\n",
    "                                        'Sub13':Kalman_error_EuclidXY[12],\n",
    "                                        'Sub14':Kalman_error_EuclidXY[13],\n",
    "                                        'Sub15':Kalman_error_EuclidXY[14],\n",
    "                                        'Sub16':Kalman_error_EuclidXY[15],\n",
    "                                        'Sub17':Kalman_error_EuclidXY[16],\n",
    "                                        'Sub18':Kalman_error_EuclidXY[17],\n",
    "                                        'Sub19':Kalman_error_EuclidXY[18],\n",
    "                                        'Sub20':Kalman_error_EuclidXY[19],\n",
    "                                        'Sub21':Kalman_error_EuclidXY[20]}, ignore_index=True)\n",
    "\n",
    "\n",
    "        df_results = df_results.append({'MMSI': my_MMSI,'Method': 'Linear', \n",
    "                                       'Sub1':Linear_error_EuclidYX[0],\n",
    "                                        'Sub2':Linear_error_EuclidYX[1],\n",
    "                                        'Sub3':Linear_error_EuclidYX[2],\n",
    "                                        'Sub4':Linear_error_EuclidYX[3],\n",
    "                                        'Sub5':Linear_error_EuclidYX[4],\n",
    "                                        'Sub6':Linear_error_EuclidYX[5],\n",
    "                                        'Sub7':Linear_error_EuclidYX[6],\n",
    "                                        'Sub8':Linear_error_EuclidYX[7],\n",
    "                                        'Sub9':Linear_error_EuclidYX[8],\n",
    "                                        'Sub10':Linear_error_EuclidYX[9],\n",
    "                                        'Sub11':Linear_error_EuclidYX[10],\n",
    "                                        'Sub12':Linear_error_EuclidYX[11],\n",
    "                                        'Sub13':Linear_error_EuclidYX[12],\n",
    "                                        'Sub14':Linear_error_EuclidYX[13],\n",
    "                                        'Sub15':Linear_error_EuclidYX[14],\n",
    "                                        'Sub16':Linear_error_EuclidYX[15],\n",
    "                                        'Sub17':Linear_error_EuclidYX[16],\n",
    "                                        'Sub18':Linear_error_EuclidYX[17],\n",
    "                                        'Sub19':Linear_error_EuclidYX[18],\n",
    "                                        'Sub20':Linear_error_EuclidYX[19],\n",
    "                                        'Sub21':Linear_error_EuclidYX[20],}, ignore_index=True)\n",
    "\n",
    "    my_csv_string =  str(\"KalmanVSlinearResults_28Oct21_\"+ str(sub_sec_count) +\".csv\")\n",
    "    df_results.to_csv(my_csv_string, index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Kalman')\n",
    "# print(len(Kalman_X_pred))\n",
    "# print(len(Kalman_Y_pred))\n",
    "# print(\"-\")\n",
    "# print(Kalman_observed_sec)\n",
    "\n",
    "# print('Linear')\n",
    "# print(pred_linear_X)\n",
    "# print(pred_linear_Y)\n",
    "# print(pred_linear_SOG)\n",
    "# print(linear_sec_ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(r\"KalmanVSlinearResults_1_21_420.csv\", index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_stats = pd.read_csv(r\"KalmanVSlinearResults_240.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(my_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Kalman_stats = my_stats.iloc[0,:]\n",
    "Linear_stats = my_stats.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kalman_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_stats.to_csv(\"All_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_csv = np.arange(300,1860,60)\n",
    "\n",
    "df_DKF_vs_LRM =  pd.read_csv(r\"KalmanVSlinearResults_240.csv\")\n",
    "for csv in my_csv:\n",
    "    my_csv_string = None\n",
    "    my_csv_string =  str(\"./Kalman TimeIntervals/KalmanVSlinearResults_\"+ str(csv) +\".csv\")\n",
    "    temp_dataset = pd.read_csv(my_csv_string)\n",
    "    df_DKF_vs_LRM = df_DKF_vs_LRM.append(temp_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_DKF_vs_LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kalman_stats = df_DKF_vs_LRM.iloc[np.arange(0,df_DKF_vs_LRM.shape[0],2),:]\n",
    "Linear_stats = df_DKF_vs_LRM.iloc[np.arange(1,df_DKF_vs_LRM.shape[0],2),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kalman_stats\n",
    "Linear_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kal_sub1 = np.average(Kalman_stats['Sub1'])\n",
    "Kal_sub2 = np.average(Kalman_stats['Sub2'])\n",
    "Kal_sub3 = np.average(Kalman_stats['Sub3'])\n",
    "Kal_sub4 = np.average(Kalman_stats['Sub4'])\n",
    "Kal_sub5 = np.average(Kalman_stats['Sub5'])\n",
    "Kal_sub6 = np.average(Kalman_stats['Sub6'])\n",
    "Kal_sub7 = np.average(Kalman_stats['Sub7'])\n",
    "Kal_sub8 = np.average(Kalman_stats['Sub8'])\n",
    "Kal_sub9 = np.average(Kalman_stats['Sub9'])\n",
    "Kal_sub10 = np.average(Kalman_stats['Sub10'])\n",
    "Kal_sub11 = np.average(Kalman_stats['Sub11'])\n",
    "Kal_sub12 = np.average(Kalman_stats['Sub12'])\n",
    "Kal_sub13 = np.average(Kalman_stats['Sub13'])\n",
    "Kal_sub14 = np.average(Kalman_stats['Sub14'])\n",
    "Kal_sub15 = np.average(Kalman_stats['Sub15'])\n",
    "Kal_sub16 = np.average(Kalman_stats['Sub16'])\n",
    "Kal_sub17 = np.average(Kalman_stats['Sub17'])\n",
    "Kal_sub18 = np.average(Kalman_stats['Sub18'])\n",
    "Kal_sub19 = np.average(Kalman_stats['Sub19'])\n",
    "Kal_sub20 = np.average(Kalman_stats['Sub20'])\n",
    "Kal_sub21 = np.average(Kalman_stats['Sub21'])\n",
    "\n",
    "\n",
    "Kalman_errors = np.array([Kal_sub1,\n",
    "                 Kal_sub2,\n",
    "                 Kal_sub3,\n",
    "                 Kal_sub4,\n",
    "                 Kal_sub5,\n",
    "                 Kal_sub6,\n",
    "                 Kal_sub7,\n",
    "                 Kal_sub8,\n",
    "                 Kal_sub9,                 \n",
    "                 Kal_sub10,\n",
    "                 Kal_sub11,\n",
    "                 Kal_sub12,\n",
    "                 Kal_sub13,\n",
    "                 Kal_sub14,\n",
    "                 Kal_sub15,\n",
    "                 Kal_sub16,\n",
    "                 Kal_sub17,\n",
    "                 Kal_sub18,\n",
    "                 Kal_sub19,\n",
    "                 Kal_sub20,\n",
    "                 Kal_sub21])\n",
    "\n",
    "Kalman_errors_STDs= np.array([\n",
    "                    np.std(Kalman_stats['Sub1']),\n",
    "                    np.std(Kalman_stats['Sub2']),\n",
    "                    np.std(Kalman_stats['Sub3']),\n",
    "                    np.std(Kalman_stats['Sub4']),\n",
    "                    np.std(Kalman_stats['Sub5']),\n",
    "                    np.std(Kalman_stats['Sub6']),\n",
    "                    np.std(Kalman_stats['Sub7']),\n",
    "                    np.std(Kalman_stats['Sub8']),\n",
    "                    np.std(Kalman_stats['Sub9']),\n",
    "                    np.std(Kalman_stats['Sub10']),\n",
    "                    np.std(Kalman_stats['Sub11']),\n",
    "                    np.std(Kalman_stats['Sub12']),\n",
    "                    np.std(Kalman_stats['Sub13']),\n",
    "                    np.std(Kalman_stats['Sub14']),\n",
    "                    np.std(Kalman_stats['Sub15']),\n",
    "                    np.std(Kalman_stats['Sub16']),\n",
    "                    np.std(Kalman_stats['Sub17']),\n",
    "                    np.std(Kalman_stats['Sub18']),\n",
    "                    np.std(Kalman_stats['Sub19']),\n",
    "                    np.std(Kalman_stats['Sub20']),\n",
    "                    np.std(Kalman_stats['Sub21'])                   ])\n",
    "\n",
    "Kalman_errors_UP = Kalman_errors +Kalman_errors_STDs\n",
    "Kalman_errors_DOWN = Kalman_errors-Kalman_errors_STDs\n",
    "\n",
    "\n",
    "Linear_sub1 = np.average(Linear_stats['Sub1'])\n",
    "Linear_sub2 = np.average(Linear_stats['Sub2'])\n",
    "Linear_sub3 = np.average(Linear_stats['Sub3'])\n",
    "Linear_sub4 = np.average(Linear_stats['Sub4'])\n",
    "Linear_sub5 = np.average(Linear_stats['Sub5'])\n",
    "Linear_sub6 = np.average(Linear_stats['Sub6'])\n",
    "Linear_sub7 = np.average(Linear_stats['Sub7'])\n",
    "Linear_sub8 = np.average(Linear_stats['Sub8'])\n",
    "Linear_sub9 = np.average(Linear_stats['Sub9'])\n",
    "Linear_sub10 = np.average(Linear_stats['Sub10'])\n",
    "Linear_sub11 = np.average(Linear_stats['Sub11'])\n",
    "Linear_sub12 = np.average(Linear_stats['Sub12'])\n",
    "Linear_sub13 = np.average(Linear_stats['Sub13'])\n",
    "Linear_sub14 = np.average(Linear_stats['Sub14'])\n",
    "Linear_sub15 = np.average(Linear_stats['Sub15'])\n",
    "Linear_sub16 = np.average(Linear_stats['Sub16'])\n",
    "Linear_sub17 = np.average(Linear_stats['Sub17'])\n",
    "Linear_sub18 = np.average(Linear_stats['Sub18'])\n",
    "Linear_sub19 = np.average(Linear_stats['Sub19'])\n",
    "Linear_sub20 = np.average(Linear_stats['Sub20'])\n",
    "Linear_sub21 = np.average(Linear_stats['Sub21'])\n",
    "\n",
    "Linear_errors = np.array([Linear_sub1,\n",
    "                 Linear_sub2,\n",
    "                 Linear_sub3,\n",
    "                 Linear_sub4,\n",
    "                 Linear_sub5,\n",
    "                 Linear_sub6,\n",
    "                 Linear_sub7,\n",
    "                 Linear_sub8,\n",
    "                 Linear_sub9,\n",
    "                 Linear_sub10,\n",
    "                 Linear_sub11,\n",
    "                 Linear_sub12,\n",
    "                 Linear_sub13,\n",
    "                 Linear_sub14,\n",
    "                 Linear_sub15,\n",
    "                 Linear_sub16,\n",
    "                 Linear_sub17,\n",
    "                 Linear_sub18,\n",
    "                 Linear_sub19,\n",
    "                 Linear_sub20,\n",
    "                 Linear_sub21])\n",
    "\n",
    "Linear_errors_STDs=  np.array([\n",
    "                    np.std(Linear_stats['Sub1']),\n",
    "                    np.std(Linear_stats['Sub2']),\n",
    "                    np.std(Linear_stats['Sub3']),\n",
    "                    np.std(Linear_stats['Sub4']),\n",
    "                    np.std(Linear_stats['Sub5']),\n",
    "                    np.std(Linear_stats['Sub6']),\n",
    "                    np.std(Linear_stats['Sub7']),\n",
    "                    np.std(Linear_stats['Sub8']),\n",
    "                    np.std(Linear_stats['Sub9']),\n",
    "                    np.std(Linear_stats['Sub10']),\n",
    "                    np.std(Linear_stats['Sub11']),\n",
    "                    np.std(Linear_stats['Sub12']),\n",
    "                    np.std(Linear_stats['Sub13']),\n",
    "                    np.std(Linear_stats['Sub14']),\n",
    "                    np.std(Linear_stats['Sub15']),\n",
    "                    np.std(Linear_stats['Sub16']),\n",
    "                    np.std(Linear_stats['Sub17']),\n",
    "                    np.std(Linear_stats['Sub18']),\n",
    "                    np.std(Linear_stats['Sub19']),\n",
    "                    np.std(Linear_stats['Sub20']),\n",
    "                    np.std(Linear_stats['Sub21'])\n",
    "                    ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Linear_errors_UP = Linear_errors +Linear_errors_STDs\n",
    "Linear_errors_DOWN =Linear_errors -Linear_errors_STDs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We are merging all the datasets to get a better average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Linear_stats)\n",
    "len(Kalman_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DKF_vs_LRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kalman_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sequence = np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21])\n",
    "mpl.rcParams['figure.figsize'] = (10,4)\n",
    "\n",
    "linear_color = \"#e76f51\"\n",
    "kalman_color = \"#005f73\"\n",
    "\n",
    "plt.plot(my_sequence,Kalman_errors,\"o-\", color = kalman_color)\n",
    "plt.plot(my_sequence,Linear_errors,\"o-\",color = linear_color)\n",
    "plt.plot(my_sequence,Kalman_errors_UP,\"--\",color = kalman_color, alpha = 1)\n",
    "plt.plot(my_sequence,Linear_errors_UP,\"--\",color = linear_color, alpha = 1)\n",
    "plt.plot(my_sequence,Kalman_errors_DOWN,\"--\",color = kalman_color, alpha = 1)\n",
    "plt.plot(my_sequence,Linear_errors_DOWN,\"--\",color = linear_color, alpha = 1)\n",
    "\n",
    "plt.fill_between(my_sequence,Kalman_errors_UP,Kalman_errors_DOWN, facecolor = kalman_color,alpha = 0.3)\n",
    "plt.fill_between(my_sequence,Linear_errors_UP,Linear_errors_DOWN, facecolor = linear_color,alpha = 0.3)\n",
    "\n",
    "# plt.fill_between(my_sequence,Kalman_errors_UP,Linear_errors_DOWN, facecolor = kalman_color,alpha = 0.9)\n",
    "\n",
    "plt.xlabel(\"Under sampling rates ($\\lambda_{s_{i}}$)\", fontsize = 14)\n",
    "plt.ylabel('Mean Euclidean Error (m)', fontsize = 14)\n",
    "plt.title('DKF and LRM prediction errors', fontsize = 18)\n",
    "\n",
    "plt.xticks(np.arange(1, 22, step=1))\n",
    "plt.yticks(size = 12)\n",
    "plt.xticks(size = 12)\n",
    "\n",
    "plt.xlim(0.9,5)\n",
    "plt.ylim(-50,300)\n",
    "#ax.set_xlabel('time [s]', fontsize='large', fontweight='bold')\n",
    "\n",
    "legend_data = ['DKF','LRM', 'DKF + $ \\sigma$', \"LRM + $\\sigma$\" ]\n",
    "plt.legend(legend_data, title = \"Models & SD\",title_fontsize = 16,loc = 'upper left', fontsize = 12, ncol = 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTest = np.array([10,20,30,40,50,60,70])\n",
    "\n",
    "for i in myTest:\n",
    "    string =  str(str(i) +\".csv\")\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(480,1860,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled.to_csv(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deepcopy the new dataset to the sampled one\n",
    "df_sampled = copy.deepcopy(pd_dataset_new)\n",
    "\n",
    "plt.plot(df_sampled['long'],df_sampled['lat'],'b.')\n",
    "plt.title(\"Extracted Linear Trajectory - MMSI:304927000 \", size = 20)\n",
    "plt.xlabel(\"X coordinate (UTM)\", size = 20)\n",
    "plt.ylabel(\"Y coordinate (UTM)\", size = 20)\n",
    "plt.yticks(size = 18)\n",
    "plt.xticks(size = 18)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0,len(df_sampled['sog']),1),df_sampled['sog'],'m.')\n",
    "plt.title(\"Speed over ground per observation - MMSI:304927000\", size = 20)\n",
    "plt.xlabel(\"Observation from extracted trajectory\", size = 20)\n",
    "plt.ylabel(\"Speed over ground (SOG)\", size = 20)\n",
    "plt.yticks(size = 18)\n",
    "plt.xticks(size = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "304927000\n",
    "arr_MMSI[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sequence = np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19])\n",
    "\n",
    "# my_index = 5\n",
    "\n",
    "# my_MMSI = arr_MMSI[my_index]\n",
    "# start = MMSI_starts[my_index] \n",
    "# end = MMSI_ends[my_index] \n",
    "\n",
    "# print(\"\\n\\n\\nMMSI NO:\",my_MMSI,\"START:\", start, \"END:\", end)\n",
    "\n",
    "# pd_dataset = df_sampled\n",
    "# lower = start\n",
    "# upper = end\n",
    "# myrange = np.arange(lower,upper,1) #to cut the part thats goint to be used\n",
    "# df_origMMSI = convert_dataset(pd_dataset.iloc[myrange,:].reset_index(drop = True),240,1)\n",
    "df_origMMSI = df_sampled\n",
    "\n",
    "Kalman_error_EuclidXY =   []\n",
    "Linear_error_EuclidYX =   []\n",
    "\n",
    "sub_sec_count = 300\n",
    "\n",
    "for sub_sample_data in my_sequence:\n",
    "\n",
    "    #print(\"\\n\\n\\n\\n\\n\\nSUB SAMPLE SIZE: \",sub_sample_data )\n",
    "    df_subMMSI = convert_dataset(pd_dataset.iloc[myrange,:].reset_index(drop = True),sub_sec_count,sub_sample_data)\n",
    "\n",
    "    Kalman_X_pred, Kalman_Y_pred, X_samp_orig, Y_samp_orig, _, _, _,_,Kalman_observed_sec = myKalman(df_subMMSI, R,Q,P_k, True)\n",
    "    #print('------------------------------------- LINEAR METHOD ---------------------------------------')\n",
    "    pred_linear_X, pred_linear_Y,pred_linear_SOG,linear_sec_ob = AIS_linear(df_subMMSI,5,True)\n",
    "    \n",
    "\n",
    "    #print('------------------------------------- KALMAN ERROR ---------------------------------------')\n",
    "    Kalman_X_MSE, Kalman_Y_MSE, Kalman_Euclid_AVG = calculate_errors(df_origMMSI,df_subMMSI,Kalman_Y_pred,\n",
    "                                                                     Kalman_X_pred,Kalman_observed_sec, \n",
    "                                                                     \"DKF errors per observed observation\"\n",
    "                                                                     ,True)\n",
    "    \n",
    "    #print('------------------------------------- LINEAR ERROR ---------------------------------------')\n",
    "    Linear_X_MSE, Linear_Y_MSE, Linear_Euclid_AVG = calculate_errors(df_origMMSI,df_subMMSI,pred_linear_X,pred_linear_Y,\n",
    "                                                                     linear_sec_ob, \n",
    "                                                                     \"LRM errors per observed observation\",\n",
    "                                                                     True)\n",
    "\n",
    "    #APPENDINGS\n",
    "\n",
    "    Kalman_error_EuclidXY.append(Kalman_Euclid_AVG)\n",
    "    Linear_error_EuclidYX.append(Linear_Euclid_AVG)\n",
    "\n",
    "Kalman_error_EuclidXY = np.array(Kalman_error_EuclidXY)\n",
    "Linear_error_EuclidYX = np.array(Linear_error_EuclidYX)\n",
    "\n",
    "df_results = df_results.append({'MMSI': my_MMSI,'Method': 'Kalman', \n",
    "                                'Sub1':Kalman_error_EuclidXY[0],\n",
    "                                'Sub2':Kalman_error_EuclidXY[1],\n",
    "                                'Sub3':Kalman_error_EuclidXY[2],\n",
    "                                'Sub4':Kalman_error_EuclidXY[3],\n",
    "                                'Sub5':Kalman_error_EuclidXY[4],\n",
    "                                'Sub6':Kalman_error_EuclidXY[5],\n",
    "                                'Sub7':Kalman_error_EuclidXY[6],\n",
    "                                'Sub8':Kalman_error_EuclidXY[7],\n",
    "                                'Sub9':Kalman_error_EuclidXY[8],\n",
    "                                'Sub10':Kalman_error_EuclidXY[9],\n",
    "                                'Sub11':Kalman_error_EuclidXY[10],\n",
    "                                'Sub12':Kalman_error_EuclidXY[11],\n",
    "                                'Sub13':Kalman_error_EuclidXY[12],\n",
    "                                'Sub14':Kalman_error_EuclidXY[13],\n",
    "                                'Sub15':Kalman_error_EuclidXY[14],\n",
    "                                'Sub16':Kalman_error_EuclidXY[15],\n",
    "                                'Sub17':Kalman_error_EuclidXY[16],\n",
    "                                'Sub18':Kalman_error_EuclidXY[17],\n",
    "                                'Sub19':Kalman_error_EuclidXY[18]}, ignore_index=True)\n",
    "\n",
    "df_results = df_results.append({'MMSI': my_MMSI,'Method': 'Linear', \n",
    "                               'Sub1':Linear_error_EuclidYX[0],\n",
    "                                'Sub2':Linear_error_EuclidYX[1],\n",
    "                                'Sub3':Linear_error_EuclidYX[2],\n",
    "                                'Sub4':Linear_error_EuclidYX[3],\n",
    "                                'Sub5':Linear_error_EuclidYX[4],\n",
    "                                'Sub6':Linear_error_EuclidYX[5],\n",
    "                                'Sub7':Linear_error_EuclidYX[6],\n",
    "                                'Sub8':Linear_error_EuclidYX[7],\n",
    "                                'Sub9':Linear_error_EuclidYX[8],\n",
    "                                'Sub10':Linear_error_EuclidYX[9],\n",
    "                                'Sub11':Linear_error_EuclidYX[10],\n",
    "                                'Sub12':Linear_error_EuclidYX[11],\n",
    "                                'Sub13':Linear_error_EuclidYX[12],\n",
    "                                'Sub14':Linear_error_EuclidYX[13],\n",
    "                                'Sub15':Linear_error_EuclidYX[14],\n",
    "                                'Sub16':Linear_error_EuclidYX[15],\n",
    "                                'Sub17':Linear_error_EuclidYX[16],\n",
    "                                'Sub18':Linear_error_EuclidYX[17],\n",
    "                                'Sub19':Linear_error_EuclidYX[18]}, ignore_index=True)\n",
    "\n",
    "# my_csv_string =  str(\"Results_FOR_\"+ my_MMSI + str(sub_sec_count) +\".csv\")\n",
    "# df_results.to_csv(my_csv_string, index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OG_DATA = pd.read_csv(r\"304927000.csv\")\n",
    "\n",
    "MMSI_test_original = convert_dataset(OG_DATA.iloc[lower:upper,:].reset_index(drop = True),240,1)\n",
    "SUBSET = convert_dataset(OG_DATA.iloc[lower:upper,:].reset_index(drop = True),240,1)\n",
    "print(lower,upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_samp_pred, Y_samp_pred, X_samp_orig, Y_samp_orig, _, _, _, _, Kalman_observed_sec = myKalman(SUBSET, R,Q,P_k,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_linear_X, pred_linear_Y,pred_linear_SOG,linear_sec_ob = AIS_linear(SUBSET,3,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig,df_sub, pred_X, pred_Y, observed_sec,myTitle, show_plots = False ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kalman_ERROR = []\n",
    "for i in np.arange(1,17):\n",
    "    kalman_each_interval = []\n",
    "    for interval in [240,300,360,420,480,540,600,660,720,780,840,900,960,1020]:\n",
    "\n",
    "        sub_sample = i\n",
    "        MMSI_test_original = convert_dataset(OG_DATA.iloc[lower:upper,:].reset_index(drop = True),interval,sub_sample)\n",
    "        SUBSET = convert_dataset(OG_DATA.iloc[lower:upper,:].reset_index(drop = True),interval,sub_sample)\n",
    "\n",
    "\n",
    "        X_samp_pred, Y_samp_pred, X_samp_orig, Y_samp_orig, _, _, _, _, Kalman_observed_sec = myKalman(SUBSET, R,Q,P_k,False)\n",
    "        Kalman_X_MSE, Kalman_Y_MSE, Kalman_Euclid_AVG, Kalman_EUC = calculate_errors(MMSI_test_original,SUBSET,Y_samp_pred, X_samp_pred,Kalman_observed_sec,\"DKF Trajectory Prediction Error per observation\", False)\n",
    "        kalman_each_interval.append(Kalman_Euclid_AVG)\n",
    "        \n",
    "    kalman_ERROR.append(np.mean(kalman_each_interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(kalman_ERROR)\n",
    "#138.1035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Kalman_Euclid_AVG,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_linear_X, pred_linear_Y,pred_linear_SOG,linear_sec_ob = AIS_linear(SUBSET,3,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRM_ERROR = []\n",
    "for i in np.arange(1,17):\n",
    "    LRM_each_interval = []\n",
    "    for interval in [240,300,360,420,480,540,600,660,720,780,840,900,960,1020]:\n",
    "        sub_sample = i\n",
    "        MMSI_test_original = convert_dataset(OG_DATA.iloc[lower:upper,:].reset_index(drop = True),interval,sub_sample)\n",
    "        SUBSET = convert_dataset(OG_DATA.iloc[lower:upper,:].reset_index(drop = True),interval,sub_sample)\n",
    "        \n",
    "        pred_linear_X, pred_linear_Y,pred_linear_SOG,linear_sec_ob = AIS_linear(SUBSET,3,False)\n",
    "        Linear_X_MSE, Linear_Y_MSE, Linear_Euclid_AVG, Linear_EUCLID = calculate_errors(MMSI_test_original,SUBSET,pred_linear_X,pred_linear_Y,\n",
    "                                                                             linear_sec_ob, \n",
    "                                                                         \"LRM Trajectory Prediction Error per observation\",\n",
    "                                                                         False)\n",
    "        LRM_each_interval.append(np.mean(Linear_Euclid_AVG))\n",
    "    LRM_ERROR.append(np.mean(LRM_each_interval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(LRM_ERROR)\n",
    "#242.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DKF_vs_LRM =  pd.read_csv(r\"KalmanVSlinearResults_240.csv\")\n",
    "df_DKF_vs_LRM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
